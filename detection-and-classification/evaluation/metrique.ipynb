{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae9badc8-eea0-45a4-90f1-b22f566e6463",
   "metadata": {},
   "source": [
    "## YOLOv8 ‚Äì Road Damage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37977d4c-1647-4061-977c-b89e97c32fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.4.2 üöÄ Python-3.10.12 torch-2.4.1+cu121 CUDA:0 (NVIDIA RTX A6000, 48570MiB)\n",
      "Model summary (fused): 72 layers, 3,006,428 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "'/home/imadb/.cache/kagglehub/datasets/alvarobasily/road-damage/versions/road_damage_yolo/dataset/dataset.yaml' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m YOLO\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mruns/detect/train4/weights/best.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/imadb/.cache/kagglehub/datasets/alvarobasily/road-damage/versions/road_damage_yolo/dataset/dataset.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m640\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmAP50-95 :\u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics\u001b[38;5;241m.\u001b[39mbox\u001b[38;5;241m.\u001b[39mmap)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmAP50    :\u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics\u001b[38;5;241m.\u001b[39mbox\u001b[38;5;241m.\u001b[39mmap50)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/ultralytics/engine/model.py:612\u001b[0m, in \u001b[0;36mModel.val\u001b[0;34m(self, validator, **kwargs)\u001b[0m\n\u001b[1;32m    609\u001b[0m args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverrides, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcustom, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m}  \u001b[38;5;66;03m# highest priority args on the right\u001b[39;00m\n\u001b[1;32m    611\u001b[0m validator \u001b[38;5;241m=\u001b[39m (validator \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_smart_load(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidator\u001b[39m\u001b[38;5;124m\"\u001b[39m))(args\u001b[38;5;241m=\u001b[39margs, _callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks)\n\u001b[0;32m--> 612\u001b[0m \u001b[43mvalidator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics \u001b[38;5;241m=\u001b[39m validator\u001b[38;5;241m.\u001b[39mmetrics\n\u001b[1;32m    614\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m validator\u001b[38;5;241m.\u001b[39mmetrics\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/ultralytics/engine/validator.py:175\u001b[0m, in \u001b[0;36mBaseValidator.__call__\u001b[0;34m(self, trainer, model)\u001b[0m\n\u001b[1;32m    172\u001b[0m     LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSetting batch=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mbatch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m input of shape (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mbatch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, 3, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimgsz\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimgsz\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata)\u001b[38;5;241m.\u001b[39mrsplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myaml\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myml\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_det_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassify\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m check_cls_dataset(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msplit)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/ultralytics/data/utils.py:400\u001b[0m, in \u001b[0;36mcheck_det_dataset\u001b[0;34m(dataset, autodownload)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_det_dataset\u001b[39m(dataset: \u001b[38;5;28mstr\u001b[39m, autodownload: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[1;32m    387\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Download, verify, and/or unzip a dataset if not found locally.\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \n\u001b[1;32m    389\u001b[0m \u001b[38;5;124;03m    This function checks the availability of a specified dataset, and if not found, it has the option to download and\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;124;03m        (dict[str, Any]): Parsed dataset information and paths.\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 400\u001b[0m     file \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;66;03m# Download (optional)\u001b[39;00m\n\u001b[1;32m    403\u001b[0m     extract_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/ultralytics/utils/checks.py:643\u001b[0m, in \u001b[0;36mcheck_file\u001b[0;34m(file, suffix, download, download_dir, hard)\u001b[0m\n\u001b[1;32m    641\u001b[0m files \u001b[38;5;241m=\u001b[39m glob\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;28mstr\u001b[39m(ROOT \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m**\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m/\u001b[39m file), recursive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m glob\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;28mstr\u001b[39m(ROOT\u001b[38;5;241m.\u001b[39mparent \u001b[38;5;241m/\u001b[39m file))  \u001b[38;5;66;03m# find file\u001b[39;00m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m files \u001b[38;5;129;01mand\u001b[39;00m hard:\n\u001b[0;32m--> 643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m does not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    644\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(files) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m hard:\n\u001b[1;32m    645\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMultiple files match \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, specify exact path: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfiles\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: '/home/imadb/.cache/kagglehub/datasets/alvarobasily/road-damage/versions/road_damage_yolo/dataset/dataset.yaml' does not exist"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"runs/detect/train4/weights/best.pt\")\n",
    "\n",
    "metrics = model.val(\n",
    "    data=\"/home/imadb/.cache/kagglehub/datasets/alvarobasily/road-damage/versions/road_damage_yolo/dataset/dataset.yaml\",\n",
    "    imgsz=640,\n",
    "    device=0\n",
    ")\n",
    "\n",
    "print(\"mAP50-95 :\", metrics.box.map)\n",
    "print(\"mAP50    :\", metrics.box.map50)\n",
    "print(\"Precision:\", metrics.box.p)\n",
    "print(\"Recall   :\", metrics.box.r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215514f8-c2b9-4a6d-a5c0-0f57c0c3f364",
   "metadata": {},
   "source": [
    "### Commentaire sur les r√©sultats (YOLOv8 ‚Äì Road Damage)\n",
    "\n",
    "Le mod√®le YOLOv8 obtient de **bons r√©sultats** pour la d√©tection des d√©g√¢ts routiers.  \n",
    "Le **mAP@50 = 0.76** montre qu‚Äôil d√©tecte correctement la majorit√© des d√©fauts, tandis que le **mAP@50‚Äì95 = 0.45** indique que la localisation des bo√Ætes est correcte mais peut encore √™tre am√©lior√©e, surtout pour les fissures fines.  \n",
    "La **pr√©cision (0.77)** signifie qu‚Äôil y a relativement peu de fausses d√©tections, et le **rappel (0.71)** montre que quelques d√©fauts peuvent encore √™tre manqu√©s.  \n",
    "Les classes **pothole** et **alligator_cracking** sont bien d√©tect√©es, alors que **lateral_cracking** reste la plus difficile.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b9f45f8-fa48-414b-ab5c-1bca760b1e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 0.50663\n",
      "Recall    : 0.11766\n",
      "mAP50     : 0.1027\n",
      "mAP50-95  : 0.05373\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results_path = \"/home/imadb/Ghiles/Projet_Ghiles/bdd_100k/runs/detect/train_micro3/results.csv\"\n",
    "\n",
    "df = pd.read_csv(results_path)\n",
    "\n",
    "# Derni√®re √©poque (celle du best.pt)\n",
    "last = df.iloc[-1]\n",
    "\n",
    "print(\"Precision :\", last[\"metrics/precision(B)\"])\n",
    "print(\"Recall    :\", last[\"metrics/recall(B)\"])\n",
    "print(\"mAP50     :\", last[\"metrics/mAP50(B)\"])\n",
    "print(\"mAP50-95  :\", last[\"metrics/mAP50-95(B)\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d395665-89db-4947-900c-35fb90438753",
   "metadata": {},
   "source": [
    "## R√©sultats du mod√®le YOLOv8 sur BDD100K\n",
    "\n",
    "Les performances du mod√®le entra√Æn√© sur le dataset **BDD100K** sont r√©sum√©es ci-dessous :\n",
    "\n",
    "- Pr√©cision (Precision) : 0.51  \n",
    "- Rappel (Recall) : 0.12  \n",
    "- mAP@50 : 0.10  \n",
    "- mAP@50‚Äì95 : 0.05  \n",
    "\n",
    "### Analyse des m√©triques\n",
    "\n",
    "La pr√©cision relativement mod√©r√©e (0.51) indique qu‚Äôenviron une d√©tection sur deux est correcte, ce qui montre que le mod√®le ne produit pas excessivement de faux positifs.  \n",
    "En revanche, le rappel tr√®s faible (0.12) signifie que le mod√®le d√©tecte seulement une petite fraction des objets pr√©sents dans les images, manquant ainsi la majorit√© des cibles.\n",
    "\n",
    "Le score mAP@50 de 0.10 r√©v√®le une capacit√© limit√©e √† d√©tecter correctement les objets, m√™me avec un seuil d‚ÄôIoU relativement permissif.  \n",
    "Le score mAP@50‚Äì95, encore plus bas (0.05), met en √©vidence une faible pr√©cision dans la localisation des bo√Ætes englobantes lorsque des crit√®res plus stricts sont appliqu√©s.\n",
    "\n",
    "### Interpr√©tation globale\n",
    "\n",
    "Ces r√©sultats montrent que, dans sa configuration actuelle, le mod√®le pr√©sente des performances faibles sur le dataset BDD100K.  \n",
    "Ce jeu de donn√©es est particuli√®rement complexe en raison de la diversit√© des sc√®nes, de la pr√©sence d‚Äôobjets de petite taille et d‚Äôun fort d√©s√©quilibre entre les classes. Comparativement au dataset Road Damage, BDD100K constitue un d√©fi nettement plus difficile et n√©cessite un entra√Ænement plus approfondi ou un mod√®le plus robuste pour obtenir de meilleures performances.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7764320-f584-48b1-b050-2f162f0583f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model existe ? True\n",
      "YAML existe ? True\n",
      "Ultralytics 8.4.2 üöÄ Python-3.10.12 torch-2.4.1+cu121 CUDA:0 (NVIDIA RTX A6000, 48570MiB)\n",
      "Model summary (fused): 72 layers, 3,007,598 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1002.0¬±186.7 MB/s, size: 51.0 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/imadb/.cache/kagglehub/datasets/solesensei/solesensei_bdd100k/versions/2/bdd100k_yolo_10cls/labels/val... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 564.4it/s 17.7s.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/imadb/.cache/kagglehub/datasets/solesensei/solesensei_bdd100k/versions/2/bdd100k_yolo_10cls/labels/val.cache\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 15.2it/s 41.1s<0.1s\n",
      "                   all      10000     185517      0.526      0.165      0.147     0.0756\n",
      "                person       3220      13261      0.344      0.386       0.32      0.139\n",
      "                 rider        515        649     0.0138    0.00154     0.0165    0.00831\n",
      "                   car       9879     102504      0.508      0.542      0.532      0.299\n",
      "                   bus       1242       1597      0.244      0.195     0.0993     0.0678\n",
      "                 truck       2689       4244      0.386      0.201      0.179      0.113\n",
      "                  bike        578       1007          1          0    0.00446    0.00146\n",
      "                 motor        334        452          1          0          0          0\n",
      "         traffic light       5653      26883      0.391      0.104      0.121     0.0338\n",
      "          traffic sign       8221      34905      0.378      0.217      0.199      0.094\n",
      "                 train         14         15          1          0          0          0\n",
      "Speed: 0.6ms preprocess, 0.6ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1m/home/imadb/Ghiles/Projet_Ghiles/runs/detect/val9\u001b[0m\n",
      "mAP50-95 : 0.07559497740728648\n",
      "mAP50    : 0.14720353909018305\n",
      "Precision: [    0.34416    0.013828     0.50778     0.24358     0.38648           1           1     0.39064     0.37778           1]\n",
      "Recall   : [    0.38579   0.0015408     0.54163     0.19537     0.20113           0           0     0.10382     0.21705           0]\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "model_path = \"/home/imadb/Ghiles/Projet_Ghiles/bdd_100k/runs/detect/train_micro3/weights/best.pt\"\n",
    "data_yaml  = \"/home/imadb/.cache/kagglehub/datasets/solesensei/solesensei_bdd100k/versions/2/bdd100k_yolo_10cls/bdd100k_10cls.yaml\"\n",
    "\n",
    "print(\"Model existe ?\", os.path.exists(model_path))\n",
    "print(\"YAML existe ?\", os.path.exists(data_yaml))\n",
    "\n",
    "model = YOLO(model_path)\n",
    "\n",
    "metrics = model.val(\n",
    "    data=data_yaml,\n",
    "    imgsz=640,\n",
    "    device=0\n",
    ")\n",
    "\n",
    "print(\"mAP50-95 :\", metrics.box.map)\n",
    "print(\"mAP50    :\", metrics.box.map50)\n",
    "print(\"Precision:\", metrics.box.p)\n",
    "print(\"Recall   :\", metrics.box.r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "038689b8-fca1-451a-a1c9-2da5b1e5e28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============== METRICS SUMMARY ================\n",
      "[SKIP] Obstacle_LAF data.yaml not found: lost_and_found_od_yolo/data.yaml\n",
      "Ultralytics 8.4.2 üöÄ Python-3.10.12 torch-2.4.1+cu121 CUDA:0 (NVIDIA RTX A6000, 48570MiB)\n",
      "Model summary (fused): 113 layers, 43,608,150 parameters, 0 gradients, 164.8 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 161.3¬±37.1 MB/s, size: 41.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/imadb/Ghiles/road work sing 1/road works sign/val/labels.cache... 50 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 50/50 11.7Mit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.7it/s 1.5s0.6s\n",
      "                   all         50        125      0.988      0.989      0.992      0.971\n",
      "Speed: 2.4ms preprocess, 11.1ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
      "Results saved to \u001b[1m/home/imadb/Ghiles/Projet_Ghiles/runs/detect/val10\u001b[0m\n",
      "RoadWorks      | P=0.988 | R=0.989 | mAP50=0.992 | mAP50-95=0.971 | data=/home/imadb/Ghiles/road work sing 1/road works sign/data.yaml\n",
      "Ultralytics 8.4.2 üöÄ Python-3.10.12 torch-2.4.1+cu121 CUDA:0 (NVIDIA RTX A6000, 48570MiB)\n",
      "Model summary (fused): 93 layers, 25,840,918 parameters, 0 gradients, 78.7 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.1¬±0.1 ms, read: 144.0¬±10.8 MB/s, size: 39.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/imadb/Ghiles/Speed bumps detection/Speed bumps detection/valid/labels.cache... 180 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 180/180 18.0Mit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 4.7it/s 2.5s0.1s\n",
      "                   all        180        182      0.938      0.874       0.92      0.579\n",
      "Speed: 1.6ms preprocess, 4.8ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Results saved to \u001b[1m/home/imadb/Ghiles/Projet_Ghiles/runs/detect/val11\u001b[0m\n",
      "SpeedBumps     | P=0.938 | R=0.874 | mAP50=0.920 | mAP50-95=0.579 | data=/home/imadb/Ghiles/Speed bumps detection/Speed bumps detection/data.yaml\n",
      "Ultralytics 8.4.2 üöÄ Python-3.10.12 torch-2.4.1+cu121 CUDA:0 (NVIDIA RTX A6000, 48570MiB)\n",
      "Model summary (fused): 93 layers, 25,840,339 parameters, 0 gradients, 78.7 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 84.7¬±26.2 MB/s, size: 18.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/imadb/Ghiles/stop_signn/stop signs/valid/labels.cache... 110 images, 2 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 110/110 11.5Mit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 7/7 3.7it/s 1.9s0.2s\n",
      "                   all        110        136      0.977      0.937      0.975      0.872\n",
      "Speed: 1.3ms preprocess, 4.8ms inference, 0.0ms loss, 3.0ms postprocess per image\n",
      "Results saved to \u001b[1m/home/imadb/Ghiles/Projet_Ghiles/runs/detect/val12\u001b[0m\n",
      "StopSign       | P=0.977 | R=0.937 | mAP50=0.975 | mAP50-95=0.872 | data=/home/imadb/Ghiles/stop_signn/stop signs/data.yaml\n",
      "[SKIP] RoadDamage data.yaml not found: /home/camembert/.cache/kagglehub/datasets/alvarobasily/road-damage/versions/road_damage_yolo/dataset/dataset.yaml\n",
      "Ultralytics 8.4.2 üöÄ Python-3.10.12 torch-2.4.1+cu121 CUDA:0 (NVIDIA RTX A6000, 48570MiB)\n",
      "Model summary (fused): 113 layers, 43,607,379 parameters, 0 gradients, 164.8 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 143.3¬±107.3 MB/s, size: 112.8 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/imadb/Ghiles/debris1/Road debrit 1/valid/labels.cache... 20 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 20/20 4.9Mit/s 0.0s\n",
      "WARNING ‚ö†Ô∏è Box and segment counts should be equal, but got len(segments) = 1, len(boxes) = 66. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 3.5it/s 0.6s0.9s\n",
      "                   all         20         66      0.662      0.621      0.605      0.372\n",
      "Speed: 2.9ms preprocess, 8.3ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1m/home/imadb/Ghiles/Projet_Ghiles/runs/detect/val13\u001b[0m\n",
      "RoadDebris1    | P=0.662 | R=0.621 | mAP50=0.605 | mAP50-95=0.372 | data=/home/imadb/Ghiles/debris1/Road debrit 1/data.yaml\n",
      "Ultralytics 8.4.2 üöÄ Python-3.10.12 torch-2.4.1+cu121 CUDA:0 (NVIDIA RTX A6000, 48570MiB)\n",
      "Model summary (fused): 113 layers, 43,608,921 parameters, 0 gradients, 164.8 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 650.2¬±296.5 MB/s, size: 93.6 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/imadb/.cache/kagglehub/datasets/saksham07gupta/road-obstacledebris-detection/versions/2/final_dataset/final_dataset/valid/labels.cache... 722 images, 20 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 722/722 104.4Mit/s 0.0s\n",
      "WARNING ‚ö†Ô∏è Box and segment counts should be equal, but got len(segments) = 2, len(boxes) = 1231. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 46/46 6.0it/s 7.7s0.2s\n",
      "                   all        722       1231      0.831      0.726       0.78      0.474\n",
      "Speed: 1.0ms preprocess, 6.5ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1m/home/imadb/Ghiles/Projet_Ghiles/runs/detect/val14\u001b[0m\n",
      "RoadObstacle   | P=0.831 | R=0.726 | mAP50=0.780 | mAP50-95=0.474 | data=/home/imadb/.cache/kagglehub/datasets/saksham07gupta/road-obstacledebris-detection/versions/2/data_fixed.yaml\n",
      "=================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "candidates = [\n",
    "    (\"Obstacle_LAF\",  \"/home/imadb/Ghiles/runs/detect/train4/weights/best.pt\"),\n",
    "    (\"RoadWorks\",     \"/home/imadb/runs/detect/RoadWorks2/weights/best.pt\"),\n",
    "    (\"SpeedBumps\",    \"/home/imadb/runs/detect/SpeedBumps/weights/best.pt\"),\n",
    "    (\"StopSign\",      \"/home/imadb/runs/detect/StopSign/weights/best.pt\"),\n",
    "    (\"RoadDamage\",    \"/home/imadb/Ghiles/Projet_Ghiles/runs/detect/train4/weights/best.pt\"),\n",
    "    (\"RoadDebris1\",   \"/home/imadb/runs/detect/RoadDebris1/weights/best.pt\"),\n",
    "    (\"RoadObstacle\",  \"/home/imadb/runs/detect/road_obstacle_yolov8l/weights/best.pt\"),\n",
    "]\n",
    "\n",
    "def find_data_yaml_from_run(weights_path: Path):\n",
    "    run_dir = weights_path.parent.parent  # .../weights/best.pt -> run_dir\n",
    "    args_yaml = run_dir / \"args.yaml\"\n",
    "    if not args_yaml.exists():\n",
    "        return None, f\"args.yaml not found: {args_yaml}\"\n",
    "    try:\n",
    "        data = yaml.safe_load(args_yaml.read_text())\n",
    "    except Exception as e:\n",
    "        return None, f\"cannot read args.yaml: {e}\"\n",
    "    data_path = data.get(\"data\", None)\n",
    "    if not data_path:\n",
    "        return None, \"data field not found in args.yaml\"\n",
    "    return Path(str(data_path)), None\n",
    "\n",
    "print(\"\\n=============== METRICS SUMMARY ================\")\n",
    "\n",
    "for name, w in candidates:\n",
    "    w = Path(w)\n",
    "    if not w.exists():\n",
    "        print(f\"[SKIP] {name} weights not found: {w}\")\n",
    "        continue\n",
    "\n",
    "    data_yaml, err = find_data_yaml_from_run(w)\n",
    "    if err:\n",
    "        print(f\"[SKIP] {name} {err}\")\n",
    "        continue\n",
    "    if not data_yaml.exists():\n",
    "        print(f\"[SKIP] {name} data.yaml not found: {data_yaml}\")\n",
    "        continue\n",
    "\n",
    "    model = YOLO(str(w))\n",
    "    metrics = model.val(\n",
    "        data=str(data_yaml),\n",
    "        device=0,\n",
    "        imgsz=640,\n",
    "        conf=0.25,\n",
    "        iou=0.70,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"{name:<14} | \"\n",
    "        f\"P={metrics.box.mp:.3f} | \"\n",
    "        f\"R={metrics.box.mr:.3f} | \"\n",
    "        f\"mAP50={metrics.box.map50:.3f} | \"\n",
    "        f\"mAP50-95={metrics.box.map:.3f} | \"\n",
    "        f\"data={data_yaml}\"\n",
    "    )\n",
    "\n",
    "print(\"=================================================\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "576af152-3f5a-4139-a0f2-854d3ebfdb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============== METRICS FROM TRAINING ===============\n",
      "\n",
      "Obstacle_LAF   | P=0.994 | R=0.969 | mAP50=0.982 | mAP50-95=0.723\n",
      "RoadWorks      | P=0.993 | R=0.981 | mAP50=0.988 | mAP50-95=0.960\n",
      "SpeedBumps     | P=0.917 | R=0.863 | mAP50=0.883 | mAP50-95=0.493\n",
      "StopSign       | P=0.957 | R=0.977 | mAP50=0.989 | mAP50-95=0.854\n",
      "RoadDamage     | P=0.629 | R=0.546 | mAP50=0.576 | mAP50-95=0.264\n",
      "RoadDebris1    | P=0.558 | R=0.667 | mAP50=0.570 | mAP50-95=0.283\n",
      "RoadObstacle   | P=0.814 | R=0.727 | mAP50=0.747 | mAP50-95=0.407\n",
      "\n",
      "====================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "runs = [\n",
    "    (\"Obstacle_LAF\",  \"/home/imadb/Ghiles/runs/detect/train4\"),\n",
    "    (\"RoadWorks\",     \"/home/imadb/runs/detect/RoadWorks2\"),\n",
    "    (\"SpeedBumps\",    \"/home/imadb/runs/detect/SpeedBumps\"),\n",
    "    (\"StopSign\",      \"/home/imadb/runs/detect/StopSign\"),\n",
    "    (\"RoadDamage\",    \"/home/imadb/Ghiles/Projet_Ghiles/runs/detect/train4\"),\n",
    "    (\"RoadDebris1\",   \"/home/imadb/runs/detect/RoadDebris1\"),\n",
    "    (\"RoadObstacle\",  \"/home/imadb/runs/detect/road_obstacle_yolov8l\"),\n",
    "]\n",
    "\n",
    "print(\"\\n=============== METRICS FROM TRAINING ===============\\n\")\n",
    "\n",
    "for name, run_dir in runs:\n",
    "    run_dir = Path(run_dir)\n",
    "    csv = run_dir / \"results.csv\"\n",
    "\n",
    "    if not csv.exists():\n",
    "        print(f\"[SKIP] {name} results.csv not found\")\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(csv)\n",
    "\n",
    "    last = df.iloc[-1]  # derni√®re epoch\n",
    "\n",
    "    print(\n",
    "        f\"{name:<14} | \"\n",
    "        f\"P={last['metrics/precision(B)']:.3f} | \"\n",
    "        f\"R={last['metrics/recall(B)']:.3f} | \"\n",
    "        f\"mAP50={last['metrics/mAP50(B)']:.3f} | \"\n",
    "        f\"mAP50-95={last['metrics/mAP50-95(B)']:.3f}\"\n",
    "    )\n",
    "\n",
    "print(\"\\n====================================================\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10b4dc63-bb99-4f1f-be15-de684083e78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== METRICS (REVAL SAME AS TRAIN) ===============\n",
      "Ultralytics 8.4.2 üöÄ Python-3.10.12 torch-2.4.1+cu121 CUDA:0 (NVIDIA RTX A6000, 48570MiB)\n",
      "Model summary (fused): 113 layers, 43,608,150 parameters, 0 gradients, 164.8 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1385.5¬±437.0 MB/s, size: 38.6 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/imadb/Ghiles/road work sing 1/road works sign/val/labels.cache... 50 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 50/50 3.9Mit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 3.0it/s 1.3s0.6s\n",
      "                   all         50        125      0.982      0.984      0.989      0.964\n",
      "Speed: 3.7ms preprocess, 7.8ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "Results saved to \u001b[1m/home/imadb/Ghiles/Projet_Ghiles/runs/detect/val15\u001b[0m\n",
      "RoadWorks    | P=0.982 | R=0.984 | mAP50=0.989 | mAP50-95=0.964\n",
      "Ultralytics 8.4.2 üöÄ Python-3.10.12 torch-2.4.1+cu121 CUDA:0 (NVIDIA RTX A6000, 48570MiB)\n",
      "Model summary (fused): 93 layers, 25,840,918 parameters, 0 gradients, 78.7 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1119.8¬±270.7 MB/s, size: 34.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/imadb/Ghiles/Speed bumps detection/Speed bumps detection/valid/labels.cache... 180 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 180/180 36.0Mit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 5.1it/s 2.3s0.1s\n",
      "                   all        180        182      0.938      0.874      0.906      0.541\n",
      "Speed: 2.1ms preprocess, 4.6ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Results saved to \u001b[1m/home/imadb/Ghiles/Projet_Ghiles/runs/detect/val16\u001b[0m\n",
      "SpeedBumps   | P=0.938 | R=0.874 | mAP50=0.906 | mAP50-95=0.541\n",
      "Ultralytics 8.4.2 üöÄ Python-3.10.12 torch-2.4.1+cu121 CUDA:0 (NVIDIA RTX A6000, 48570MiB)\n",
      "Model summary (fused): 93 layers, 25,840,339 parameters, 0 gradients, 78.7 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 844.6¬±186.5 MB/s, size: 25.9 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/imadb/Ghiles/stop_signn/stop signs/valid/labels.cache... 110 images, 2 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 110/110 15.4Mit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 7/7 4.1it/s 1.7s0.2s\n",
      "                   all        110        136      0.977      0.937      0.982      0.861\n",
      "Speed: 2.5ms preprocess, 4.9ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Results saved to \u001b[1m/home/imadb/Ghiles/Projet_Ghiles/runs/detect/val17\u001b[0m\n",
      "StopSign     | P=0.977 | R=0.937 | mAP50=0.982 | mAP50-95=0.861\n",
      "Ultralytics 8.4.2 üöÄ Python-3.10.12 torch-2.4.1+cu121 CUDA:0 (NVIDIA RTX A6000, 48570MiB)\n",
      "Model summary (fused): 113 layers, 43,607,379 parameters, 0 gradients, 164.8 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 949.3¬±458.9 MB/s, size: 65.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/imadb/Ghiles/debris1/Road debrit 1/valid/labels.cache... 20 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 20/20 2.2Mit/s 0.0s\n",
      "WARNING ‚ö†Ô∏è Box and segment counts should be equal, but got len(segments) = 1, len(boxes) = 66. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 4.3it/s 0.5s1.1s\n",
      "                   all         20         66      0.663      0.621      0.588      0.318\n",
      "Speed: 2.0ms preprocess, 5.4ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1m/home/imadb/Ghiles/Projet_Ghiles/runs/detect/val18\u001b[0m\n",
      "RoadDebris1  | P=0.663 | R=0.621 | mAP50=0.588 | mAP50-95=0.318\n",
      "Ultralytics 8.4.2 üöÄ Python-3.10.12 torch-2.4.1+cu121 CUDA:0 (NVIDIA RTX A6000, 48570MiB)\n",
      "Model summary (fused): 113 layers, 43,608,921 parameters, 0 gradients, 164.8 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1863.8¬±924.8 MB/s, size: 119.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/imadb/.cache/kagglehub/datasets/saksham07gupta/road-obstacledebris-detection/versions/2/final_dataset/final_dataset/valid/labels.cache... 722 images, 20 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 722/722 108.2Mit/s 0.0s\n",
      "WARNING ‚ö†Ô∏è Box and segment counts should be equal, but got len(segments) = 2, len(boxes) = 1231. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 46/46 3.4it/s 13.3s0.3s\n",
      "                   all        722       1231      0.798      0.738      0.776      0.425\n",
      "Speed: 1.8ms preprocess, 13.6ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1m/home/imadb/Ghiles/Projet_Ghiles/runs/detect/val19\u001b[0m\n",
      "RoadObstacle | P=0.798 | R=0.738 | mAP50=0.776 | mAP50-95=0.425\n",
      "=============================================================\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "candidates = [\n",
    "    (\"RoadWorks\",     \"/home/imadb/runs/detect/RoadWorks2/weights/best.pt\"),\n",
    "    (\"SpeedBumps\",    \"/home/imadb/runs/detect/SpeedBumps/weights/best.pt\"),\n",
    "    (\"StopSign\",      \"/home/imadb/runs/detect/StopSign/weights/best.pt\"),\n",
    "    (\"RoadDebris1\",   \"/home/imadb/runs/detect/RoadDebris1/weights/best.pt\"),\n",
    "    (\"RoadObstacle\",  \"/home/imadb/runs/detect/road_obstacle_yolov8l/weights/best.pt\"),\n",
    "]\n",
    "\n",
    "def load_args(weights_path: Path):\n",
    "    run_dir = weights_path.parent.parent\n",
    "    args_yaml = run_dir / \"args.yaml\"\n",
    "    if not args_yaml.exists():\n",
    "        return None, run_dir\n",
    "    return yaml.safe_load(args_yaml.read_text()), run_dir\n",
    "\n",
    "print(\"=============== METRICS (REVAL SAME AS TRAIN) ===============\")\n",
    "for name, w in candidates:\n",
    "    w = Path(w)\n",
    "    if not w.exists():\n",
    "        print(f\"[SKIP] {name} weights not found\")\n",
    "        continue\n",
    "\n",
    "    args, run_dir = load_args(w)\n",
    "    if args is None:\n",
    "        print(f\"[SKIP] {name} args.yaml not found in {run_dir}\")\n",
    "        continue\n",
    "\n",
    "    data = Path(str(args.get(\"data\", \"\")))\n",
    "    if not data.is_absolute():\n",
    "        data = (run_dir / data).resolve()\n",
    "\n",
    "    if not data.exists():\n",
    "        print(f\"[SKIP] {name} data.yaml not found: {data}\")\n",
    "        continue\n",
    "\n",
    "    imgsz = args.get(\"imgsz\", 640)\n",
    "    conf  = args.get(\"conf\", 0.001)   # training val often uses low conf internally\n",
    "    iou   = args.get(\"iou\", 0.7)\n",
    "\n",
    "    model = YOLO(str(w))\n",
    "    m = model.val(data=str(data), imgsz=imgsz, conf=conf, iou=iou, device=0, verbose=False)\n",
    "\n",
    "    print(f\"{name:<12} | P={m.box.mp:.3f} | R={m.box.mr:.3f} | mAP50={m.box.map50:.3f} | mAP50-95={m.box.map:.3f}\")\n",
    "print(\"=============================================================\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
