{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e23b074c-ff1b-4f11-a371-9241a4ed5015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RoadWorks detections\n",
      "cones 0.87 (342,325,357,359)\n",
      "cones 0.87 (325,323,336,350)\n",
      "cones 0.55 (334,309,343,328)\n",
      "\n",
      "SpeedBumps detections\n",
      "none\n",
      "\n",
      "StopSign detections\n",
      "none\n",
      "\n",
      "RoadDamage detections\n",
      "none\n",
      "\n",
      "RoadDebris1 detections\n",
      "object 0.78 (309,469,427,583)\n",
      "\n",
      "RoadObstacle detections\n",
      "road_block 0.57 (314,312,364,359)\n",
      "road_block 0.55 (330,312,365,361)\n",
      "\n",
      "Detections before NMS: 6\n",
      "Detections after  NMS: 5\n",
      "Saved: result_all_models_nms.jpg\n",
      "\n",
      "Summary\n",
      "RoadWorks | cones | 0.87 | (342,325,357,359)\n",
      "RoadWorks | cones | 0.87 | (325,323,336,350)\n",
      "RoadDebris1 | object | 0.78 | (309,469,427,583)\n",
      "RoadObstacle | road_block | 0.57 | (314,312,364,359)\n",
      "RoadWorks | cones | 0.55 | (334,309,343,328)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "def load_model(name, weight_path, color):\n",
    "    p = Path(weight_path)\n",
    "    if not p.exists():\n",
    "        print(f\"Model missing, skipped: {name} -> {weight_path}\")\n",
    "        return None\n",
    "    return {\"name\": name, \"model\": YOLO(str(p)), \"color\": color}\n",
    "\n",
    "def iou_xyxy(a, b):\n",
    "    ax1, ay1, ax2, ay2 = a\n",
    "    bx1, by1, bx2, by2 = b\n",
    "    inter_x1 = max(ax1, bx1)\n",
    "    inter_y1 = max(ay1, by1)\n",
    "    inter_x2 = min(ax2, bx2)\n",
    "    inter_y2 = min(ay2, by2)\n",
    "    inter_w = max(0, inter_x2 - inter_x1)\n",
    "    inter_h = max(0, inter_y2 - inter_y1)\n",
    "    inter = inter_w * inter_h\n",
    "    area_a = max(0, ax2 - ax1) * max(0, ay2 - ay1)\n",
    "    area_b = max(0, bx2 - bx1) * max(0, by2 - by1)\n",
    "    union = area_a + area_b - inter + 1e-9\n",
    "    return inter / union\n",
    "\n",
    "def global_nms(dets, iou_thr=0.50):\n",
    "    dets = sorted(dets, key=lambda d: d[\"conf\"], reverse=True)\n",
    "    keep = []\n",
    "    for d in dets:\n",
    "        ok = True\n",
    "        for k in keep:\n",
    "            if iou_xyxy(d[\"bbox\"], k[\"bbox\"]) >= iou_thr:\n",
    "                ok = False\n",
    "                break\n",
    "        if ok:\n",
    "            keep.append(d)\n",
    "    return keep\n",
    "\n",
    "candidates = [\n",
    "    (\"RoadWorks\",     \"/home/imadb/runs/detect/RoadWorks2/weights/best.pt\",                   (0, 255, 0)),\n",
    "    (\"SpeedBumps\",    \"/home/imadb/runs/detect/SpeedBumps/weights/best.pt\",                   (255, 0, 0)),\n",
    "    (\"StopSign\",      \"/home/imadb/runs/detect/StopSign/weights/best.pt\",                     (0, 0, 255)),\n",
    "    (\"RoadDamage\",    \"/home/imadb/Ghiles/Projet_Ghiles/runs/detect/train4/weights/best.pt\",  (255, 255, 0)),\n",
    "    (\"RoadDebris1\",   \"/home/imadb/runs/detect/RoadDebris1/weights/best.pt\",                  (255, 0, 255)),\n",
    "    (\"RoadObstacle\",  \"/home/imadb/runs/detect/road_obstacle_yolov8l/weights/best.pt\",        (0, 128, 255)),\n",
    "]\n",
    "\n",
    "models = []\n",
    "for name, path, color in candidates:\n",
    "    m = load_model(name, path, color)\n",
    "    if m:\n",
    "        models.append(m)\n",
    "\n",
    "assert len(models) > 0, \"No valid models loaded\"\n",
    "\n",
    "img_path = \"/home/imadb/Ghiles/debris2/6.JPG\"\n",
    "assert os.path.exists(img_path), f\"Image not found: {img_path}\"\n",
    "\n",
    "CONF = 0.4\n",
    "IOU = 0.70\n",
    "NMS_IOU = 0.50\n",
    "\n",
    "all_detections = []\n",
    "\n",
    "for item in models:\n",
    "    model_name = item[\"name\"]\n",
    "    model = item[\"model\"]\n",
    "    color = item[\"color\"]\n",
    "\n",
    "    results = model(img_path, conf=CONF, iou=IOU, device=0, verbose=False)[0]\n",
    "\n",
    "    print(f\"\\n{model_name} detections\")\n",
    "    if results.boxes is None or len(results.boxes) == 0:\n",
    "        print(\"none\")\n",
    "        continue\n",
    "\n",
    "    for box in results.boxes:\n",
    "        cls = int(box.cls)\n",
    "        cls_name = results.names[cls]\n",
    "        conf = float(box.conf)\n",
    "        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)\n",
    "\n",
    "        print(f\"{cls_name} {conf:.2f} ({x1},{y1},{x2},{y2})\")\n",
    "\n",
    "        all_detections.append({\n",
    "            \"model\": model_name,\n",
    "            \"class\": cls_name,\n",
    "            \"conf\": conf,\n",
    "            \"bbox\": (x1, y1, x2, y2),\n",
    "            \"color\": color\n",
    "        })\n",
    "\n",
    "filtered = global_nms(all_detections, iou_thr=NMS_IOU)\n",
    "\n",
    "img = cv2.imread(img_path)\n",
    "assert img is not None, \"Image read failed\"\n",
    "\n",
    "for d in filtered:\n",
    "    x1, y1, x2, y2 = d[\"bbox\"]\n",
    "    color = d[\"color\"]\n",
    "    label = f\"{d['model']}:{d['class']} {d['conf']:.2f}\"\n",
    "\n",
    "    cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)\n",
    "    cv2.putText(\n",
    "        img,\n",
    "        label,\n",
    "        (x1, max(15, y1 - 5)),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        0.55,\n",
    "        color,\n",
    "        2,\n",
    "        cv2.LINE_AA\n",
    "    )\n",
    "\n",
    "out_path = \"result_all_models_nms.jpg\"\n",
    "cv2.imwrite(out_path, img)\n",
    "\n",
    "print(f\"\\nDetections before NMS: {len(all_detections)}\")\n",
    "print(f\"Detections after  NMS: {len(filtered)}\")\n",
    "print(\"Saved:\", out_path)\n",
    "\n",
    "print(\"\\nSummary\")\n",
    "if not filtered:\n",
    "    print(\"no detections\")\n",
    "else:\n",
    "    filtered = sorted(filtered, key=lambda d: d[\"conf\"], reverse=True)\n",
    "    for d in filtered:\n",
    "        x1, y1, x2, y2 = d[\"bbox\"]\n",
    "        print(f\"{d['model']} | {d['class']} | {d['conf']:.2f} | ({x1},{y1},{x2},{y2})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a7bc5672-0054-4d00-bd9f-9bc2bf276153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input : 13588981_3840_2160_30fps.mp4\n",
      "Output: output_detected.avi (3840x2160 @ 29.97 fps)\n",
      "Processed 100 frames...\n",
      "Processed 200 frames...\n",
      "Processed 300 frames...\n",
      "Processed 400 frames...\n",
      "Processed 500 frames...\n",
      "Saved: output_detected.avi\n",
      "Tip: open with VLC -> vlc output_detected.avi\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "def load_model(name, weight_path, color):\n",
    "    p = Path(weight_path)\n",
    "    if not p.exists():\n",
    "        print(f\"Model missing, skipped: {name} -> {weight_path}\")\n",
    "        return None\n",
    "    return {\"name\": name, \"model\": YOLO(str(p)), \"color\": color}\n",
    "\n",
    "def iou_xyxy(a, b):\n",
    "    ax1, ay1, ax2, ay2 = a\n",
    "    bx1, by1, bx2, by2 = b\n",
    "    inter_x1 = max(ax1, bx1)\n",
    "    inter_y1 = max(ay1, by1)\n",
    "    inter_x2 = min(ax2, bx2)\n",
    "    inter_y2 = min(ay2, by2)\n",
    "    inter_w = max(0, inter_x2 - inter_x1)\n",
    "    inter_h = max(0, inter_y2 - inter_y1)\n",
    "    inter = inter_w * inter_h\n",
    "    area_a = max(0, ax2 - ax1) * max(0, ay2 - ay1)\n",
    "    area_b = max(0, bx2 - bx1) * max(0, by2 - by1)\n",
    "    union = area_a + area_b - inter + 1e-9\n",
    "    return inter / union\n",
    "\n",
    "def global_nms(dets, iou_thr=0.50):\n",
    "    dets = sorted(dets, key=lambda d: d[\"conf\"], reverse=True)\n",
    "    keep = []\n",
    "    for d in dets:\n",
    "        ok = True\n",
    "        for k in keep:\n",
    "            if iou_xyxy(d[\"bbox\"], k[\"bbox\"]) >= iou_thr:\n",
    "                ok = False\n",
    "                break\n",
    "        if ok:\n",
    "            keep.append(d)\n",
    "    return keep\n",
    "\n",
    "def clamp_bbox(x1, y1, x2, y2, w, h):\n",
    "    x1 = max(0, min(int(x1), w - 1))\n",
    "    y1 = max(0, min(int(y1), h - 1))\n",
    "    x2 = max(0, min(int(x2), w - 1))\n",
    "    y2 = max(0, min(int(y2), h - 1))\n",
    "    # assure x1<=x2, y1<=y2\n",
    "    if x2 < x1: x1, x2 = x2, x1\n",
    "    if y2 < y1: y1, y2 = y2, y1\n",
    "    return x1, y1, x2, y2\n",
    "\n",
    "# Config \n",
    "candidates = [\n",
    "    (\"RoadWorks\",     \"/home/imadb/runs/detect/RoadWorks2/weights/best.pt\",                   (0, 255, 0)),\n",
    "    (\"SpeedBumps\",    \"/home/imadb/runs/detect/SpeedBumps/weights/best.pt\",                   (255, 0, 0)),\n",
    "    (#\"StopSign\",      \"/home/imadb/runs/detect/StopSign/weights/best.pt\",                     (0, 0, 255)),\n",
    "    (\"RoadDamage\",    \"/home/imadb/Ghiles/Projet_Ghiles/runs/detect/train4/weights/best.pt\",  (255, 255, 0)),\n",
    "    (#\"RoadDebris1\",   \"/home/imadb/runs/detect/RoadDebris1/weights/best.pt\",                  (255, 0, 255)),\n",
    "    (\"RoadObstacle\",  \"/home/imadb/runs/detect/road_obstacle_yolov8l/weights/best.pt\",        (0, 128, 255)),\n",
    "]\n",
    "\n",
    "#  Paramètres YOLO\n",
    "CONF = 0.20      \n",
    "IOU = 0.65\n",
    "NMS_IOU = 0.50\n",
    "DEVICE = 0       # 0 = GPU, sinon \"cpu\"\n",
    "\n",
    "# Vidéos\n",
    "input_video = \"13588981_3840_2160_30fps.mp4\"   \n",
    "output_video = \"output_detected.avi\"          \n",
    "\n",
    "#  Load models\n",
    "models = []\n",
    "for name, path, color in candidates:\n",
    "    m = load_model(name, path, color)\n",
    "    if m:\n",
    "        models.append(m)\n",
    "assert len(models) > 0, \"No valid models loaded\"\n",
    "\n",
    "# Video IO \n",
    "assert os.path.exists(input_video), f\"Video not found: {input_video}\"\n",
    "\n",
    "cap = cv2.VideoCapture(input_video)\n",
    "assert cap.isOpened(), \"Could not open input video\"\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "if fps is None or fps <= 1:\n",
    "    fps = 25.0  # fallback\n",
    "\n",
    "w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Codec robuste : XVID dans AVI\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "writer = cv2.VideoWriter(output_video, fourcc, fps, (w, h))\n",
    "assert writer.isOpened(), \"Could not open output writer (try another codec)\"\n",
    "\n",
    "print(f\"Input : {input_video}\")\n",
    "print(f\"Output: {output_video} ({w}x{h} @ {fps:.2f} fps)\")\n",
    "\n",
    "# Process \n",
    "frame_id = 0\n",
    "while True:\n",
    "    ok, frame = cap.read()\n",
    "    if not ok:\n",
    "        break\n",
    "    frame_id += 1\n",
    "\n",
    "    all_detections = []\n",
    "\n",
    "    for item in models:\n",
    "        model_name = item[\"name\"]\n",
    "        model = item[\"model\"]\n",
    "        color = item[\"color\"]\n",
    "\n",
    "        # inference\n",
    "        results = model(frame, conf=CONF, iou=IOU, device=DEVICE, verbose=False)[0]\n",
    "\n",
    "        if results.boxes is None or len(results.boxes) == 0:\n",
    "            continue\n",
    "\n",
    "        for box in results.boxes:\n",
    "            cls = int(box.cls)\n",
    "            cls_name = results.names[cls]\n",
    "            conf = float(box.conf)\n",
    "            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "\n",
    "            x1, y1, x2, y2 = clamp_bbox(x1, y1, x2, y2, w, h)\n",
    "\n",
    "            all_detections.append({\n",
    "                \"model\": model_name,\n",
    "                \"class\": cls_name,\n",
    "                \"conf\": conf,\n",
    "                \"bbox\": (x1, y1, x2, y2),\n",
    "                \"color\": color\n",
    "            })\n",
    "\n",
    "    # NMS global (tous modèles)\n",
    "    filtered = global_nms(all_detections, iou_thr=NMS_IOU)\n",
    "\n",
    "    # dessin\n",
    "    for d in filtered:\n",
    "        x1, y1, x2, y2 = d[\"bbox\"]\n",
    "        color = d[\"color\"]\n",
    "        label = f\"{d['model']}:{d['class']} {d['conf']:.2f}\"\n",
    "\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "        cv2.putText(\n",
    "            frame,\n",
    "            label,\n",
    "            (x1, max(15, y1 - 6)),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.55,\n",
    "            color,\n",
    "            2,\n",
    "            cv2.LINE_AA\n",
    "        )\n",
    "\n",
    "    writer.write(frame)\n",
    "\n",
    "    # petit log toutes les 100 frames\n",
    "    if frame_id % 100 == 0:\n",
    "        print(f\"Processed {frame_id} frames...\")\n",
    "\n",
    "cap.release()\n",
    "writer.release()\n",
    "\n",
    "print(\"Saved:\", output_video)\n",
    "print(\"Tip: open with VLC -> vlc output_detected.avi\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
